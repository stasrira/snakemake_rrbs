# the following global conifg variable are being used across different rules
debug: False # this variable defines if "temp" objects will be marked as temp and deleted. If set to True, temp objects won't be marked as temp and won't be deleted. False is default.
help: False # if set to True, it will display help instructions and print out all config variables and their defaut values
data_path: # /sc/arion/projects/sealfs01a/stas/local/snakemake_alternative_splicing/data_to_process
data_path_required_folders: ['fastq_raw']
raw_data_file_ext: ".fastq.gz"  # leading dot is required
samplesToIgnore: # by default no samples will be ignored
ref_data_path: /sc/arion/projects/sealfs01a/german/refdata/
motrpac_ref_data: motrpac_refdata
motrpac_ref_data_genom_dir: hg38_gencode_v30
# alt_sl_ref_data: AS
# alt_sl_ref_data_genom_dir: # if no value provided, the value of "motrpac_ref_data_genom_dir" will be used

methcap: False  # defines details of processing of some steps (trim, qc_final)

create_rds_for_rscripts: False  # if set to True, an RDS file will be created for testing participating rules utilizing R scripts

# metadata_db_study_id: # int value is expected. If set to None (default), default study_id will be identified automatically based on aliquot_id assignments in the DB. If a specific id is given, it will be used to retrive data from the database.
# metadata_db_center_id: # int value is expected. If set to None (default), default center_id will be identified automatically based on aliquot_id assignments in the DB. If a specific id is given, it will be used to retrive data from the database.

# python2_path: "/sc/arion/projects/sealfs01a/stas/conda/local_envs/snakemake3_py2/bin/python"
conda_envs_path: /sc/arion/projects/sealfs01a/stas/conda/local_envs
# python2_env_name: "" # keep blank to force snakemake to create an environment dynamically or reuse the previously created one # snakemake3_mamba4_py2  # "6f36a259f377df6a183ab7c1b570d601_"  # snakemake3_mamba4_py2_GN  
# python2_env_config: conda_envs/ngscheckmate_python2.yml
print_prerun_info: True  # if set to True (default) the collected prerun info will be printed to stdout. If set to False, no printing will be done - this is required to print the DAG diagram
pipeline_info_file: "pipeline_info.txt"
pipeline_warning_file: "pipeline_warning.txt"

# defines file types expected by the workflow
file_types: 
    - {name: R1, required: True}  # R1
    - {name: R2, required: False}  # R2
    - {name: I1, required: False}  # I1

# defines file type groups that are used in the workflow
file_type_groups:
    R1R2: ['R1', 'R2']
    R1I1: ['R1', 'I1']
    
# suppa_events: ['A3', 'A5', 'RI', 'SE']
# suppa_file_ext: ['txt'] # ['txt', 'pkl']
# # suppa_events_compiled_file_ext: ['pkl', 'pkl', 'pkl', 'txt']
# rmats_events: ['A3SS', 'A5SS', 'RI', 'SE']  # 'MXE'
# rmats_file_ext: ['txt'] # ['txt', 'pkl']
# # rmats_events_compiled_file_ext: ['txt', 'txt', 'txt', 'txt']
# spladder_events: ['exon_skip','intron_retention','alt_3prime','alt_5prime','mutex_exons']  # all members of this list should have 2 parts separated by the underscore
# spladder_events_long_execution: ['mult_exon_skip']  # all members of this list should have 3 parts separated by the underscore
# spladder_chunk_size: 2 
# spladder_events_ase_edge_limit: 500  # (default value is 500) it is used for spladder_call_events and spladder_call_events_long_execution rules
# spladder_events_ase_edge_limit_min: 300 # minimum ase_edge_limit value that can be accepted from a user
# spladder_events_ase_edge_limit_decrease_step: 100 # value to be used to decrease the ase_edge_limit for rerun attempts of the spladder_call_event rule

# rmats metadata contrast file related
# rmats contrast file is expected to have 2 columns with the first one containing sample ids and the second containing 1 for b1 assignment and 2 for b2 assignment
# rmats_contrast_file: metadata/rmats_contrast.tsv  # expected location of the rmats contrast metadata file
# rmats_default_contrast: b1
# rmats_min_b1_qty: 2 # 2
# rmats_min_b2_qty: 2 # 2

# send email default parameters
email:
    email_subject: "RRBS pipeline completed {}"
    email_body_success_template: 'Successful completion of the RRBS pipeline for {} samples with the data_path: {}. Log file for the execution is located at: {} (size: |log_size|). Attached are log, info and warning files from the run. Note: files over {} MB in size will not be attached to the email.'
    email_body_error_template: 'Errors were reported during execution of the RRBS pipeline{} with the data_path: {}. The log file for the execution is located at: {}. Note: log files over {} MB in size will not be attached to the email.'
    email_attachment_max_size: 10 # in MB

# list of conda environments used by the pipeline
conda_envs:
    main_tools: 'conda_envs/main_tools_py3.yml'
    bismark: 'conda_envs/bismark.yml'
    trim_galore: 'conda_envs/trim_galore.yml'  # includes fastqc
    # rmats: 'conda_envs/rmats.yml'
    # rmats_turbo: 'conda_envs/rmats_turbo.yml'
    # leafcutter: 'conda_envs/leafcutter_py2.yml'
    python2: 'conda_envs/ngscheckmate_python2.yml'
    multiqc: 'conda_envs/multiqc.yml'  # multiqc_1.14.yml 
    cutadapt: 'conda_envs/cutadapt.yml'  # 'conda_envs/main_tools_py3_original.yml'  # 'conda_envs/cutadapt.yml'
    # telescope: 'conda_envs/telescope_notiterable_fix.yml'  # contains installation of telescope ran from a fork of main project with a fix of the issue
    
resources:
    # the maximum memory to be allocated for any rule with dynamically increased memory based on the attempt number
    max_memory: 350000 # 350GB
    max_himem: 1400000 # 1.4 TB
    regular_queue: "premium"  # name of the LSF queue for regular steps
    long_queue: "long"  # name of the LSF queue for long running steps
    max_regular_walltime: 144  # hours
    max_long_walltime: 336  # hours
    min_walltime: 24  # minimum walltime value to be used despite the sample count

database:
    connection:
        mdb_conn_str: Driver=|db_driver|;Server=|server|;Database=|db_name|;UID=|db_user_name|;PWD=|db_user_pwd|;TrustServerCertificate=yes;  # Encrypt=no; TrustServerCertificate=yes;
        env_db_driver: SNAKEMAKE_DB_DRIVER  # name of the environment variable where from to get the value
        env_db_server: SNAKEMAKE_DB_SERVER  # name of the environment variable where from to get the value
        env_db_name: SNAKEMAKE_DB_DATABASE  # name of the environment variable where from to get the value
        env_db_user_name: SNAKEMAKE_DB_USER  # name of the environment variable where from to get the value
        env_db_user_pwd: SNAKEMAKE_DB_PWD  # name of the environment variable where from to get the value
        db_driver_plh: "|db_driver|"
        server_plh: "|server|"
        dbname_plh: "|db_name|"
        user_name_plh: "|db_user_name|"
        user_pwd_plh: "|db_user_pwd|"
        
# config settings defined per a rule scope
rules:
    fastqc_raw:
        memory: 40000
    validate_fastqI1_umi_sequence_lenght:
        memory: 10000
        umi_length: 8
    bismark_work:
        threads: 16  # Y's code using 24 and dividing it by 4 in the script before calling the tool
        single_host: True
        memory: 15000
        walltime: "48:00"
    bismark_lambda:
        threads: 16  # Y's code using 24 and dividing it by 4 in the script before calling the tool
        single_host: True
        memory: 15000
        walltime: "48:00"
    bismark_sort:
        threads: 4
        single_host: True
        memory: 2000
        # walltime: "24:00"
    bismark_umi_format:
        threads: 8
        single_host: True
        memory: 4000
    bismark_dedup:
        memory: 2000
        walltime: "2:00"
    bismark_methylation_extractor:
        # threads: 4
        single_host: True
        memory: 1000
        walltime: "2:00"
    bismark_report:
        memory: 1000
        walltime: "2:00"
    bismark_summary:
        memory: 2000
        walltime: "2:00"
    bismark_lambda_summary:
        memory: 2000
        walltime: "2:00"
    bismark_4strand_report:
        memory: 2000
        walltime: "2:00"
    bismark_lambda_4strand_report:
        memory: 2000
        walltime: "2:00"
    bismark_chr_info:
        threads: 4
        single_host: True
        memory: 1200
        walltime: "2:00"
    UMI_attach_R1:
        memory: 20000
        single_host: True
    UMI_attach_R2:
        memory: 20000
        single_host: True
    trim:
        index_adapter: "AGATCGGAAGAGC"
        index2_adapter: "AAATCAAAAAAAC"
        # minimum_length: 20
    fastqc_trim:
        memory: 40000
    phix:
        memory: 6000  # use 6000 b/c host=1
        threads: 6  # 12 # 6
        single_host: True
    trim_umi:
        memory: 8000  # 6000
        threads: 4
        single_host: True
    multiqc_fastqc_raw:
        memory: 30000
        retries: 4
    multiqc_fastqc_trim:
        memory: 30000
        retries: 4
